{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./tweets.csv')\n",
    "df.date = pd.to_datetime(df.date)\n",
    "df = df[~df.text.str.startswith('rt ')]\n",
    "df = df[~df.text.str.startswith('RT')]\n",
    "df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>Denying climate change is dangerous. Join @OFA...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>The American Bar Association gave Judge Garlan...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>We need a fully functional Supreme Court. Edit...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>Cynics, take note: When we #ActOnClimate, we b...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-10-13</td>\n",
       "      <td>\"That’s how we will overcome the challenges we...</td>\n",
       "      <td>BarackObama</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text       author\n",
       "0 2016-10-14  Denying climate change is dangerous. Join @OFA...  BarackObama\n",
       "1 2016-10-14  The American Bar Association gave Judge Garlan...  BarackObama\n",
       "2 2016-10-14  We need a fully functional Supreme Court. Edit...  BarackObama\n",
       "3 2016-10-14  Cynics, take note: When we #ActOnClimate, we b...  BarackObama\n",
       "4 2016-10-13  \"That’s how we will overcome the challenges we...  BarackObama"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "BarackObama        9126\n",
       "DonaldTrump       14310\n",
       "HillaryClinton     5654\n",
       "Name: author, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('author').author.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing \n",
    "\n",
    "- lowercase \n",
    "- rid special chars (except #)\n",
    "- rid punctuation \n",
    "- rid stop words\n",
    "- remove links\n",
    "- create bigrams and unigrams \n",
    "- remove words occuring < 3 times "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"$%&\\'()*+,-./:;<=>?[\\\\]^_`{|}~—”“…‘¯–’․️\\u200b―'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "punc = string.punctuation.replace('#', '')\n",
    "punc = punc.replace('@', '')\n",
    "punc += '—'\n",
    "punc += '”'\n",
    "punc += '“' \n",
    "punc += '…' \n",
    "punc += '‘'\n",
    "punc += '¯'\n",
    "punc += '–'\n",
    "punc += '’'\n",
    "punc += '․'\n",
    "punc += '️'\n",
    "punc += '\\u200b'\n",
    "# punc += '\\u200e',\n",
    "# punc += '\\u200f',\n",
    "punc +='―'\n",
    "\n",
    "punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def preprocess(x): \n",
    "    x = x.lower()\n",
    "    #replace links \n",
    "    for word in x.split(): \n",
    "        if 'pic.twitter' in word:\n",
    "            x = x.replace(word, '')\n",
    "        if 'http' in word: \n",
    "            x = x.replace(word, '') \n",
    "    #replace special chars \n",
    "    for char in punc: \n",
    "        x = x.replace(char, '')\n",
    "    x = ' '.join(x.split()) #get rid of white spaces \n",
    "\n",
    "    return x\n",
    "    \n",
    "df['process_text'] = df.text.apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29090, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>process_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>Denying climate change is dangerous. Join @OFA...</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>denying climate change is dangerous join @ofa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>The American Bar Association gave Judge Garlan...</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>the american bar association gave judge garlan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text       author  \\\n",
       "0 2016-10-14  Denying climate change is dangerous. Join @OFA...  BarackObama   \n",
       "1 2016-10-14  The American Bar Association gave Judge Garlan...  BarackObama   \n",
       "\n",
       "                                        process_text  \n",
       "0  denying climate change is dangerous join @ofa ...  \n",
       "1  the american bar association gave judge garlan...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (df.shape)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurrences</th>\n",
       "      <th>term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9067</th>\n",
       "      <td>4137</td>\n",
       "      <td>president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>3792</td>\n",
       "      <td>obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9101</th>\n",
       "      <td>2695</td>\n",
       "      <td>president obama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4888</th>\n",
       "      <td>2086</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12008</th>\n",
       "      <td>1922</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       occurrences             term\n",
       "9067          4137        president\n",
       "7996          3792            obama\n",
       "9101          2695  president obama\n",
       "4888          2086            great\n",
       "12008         1922            trump"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### word counts ### \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "cvec = CountVectorizer(stop_words='english', min_df=4, max_df=.25, ngram_range=(1,2))\n",
    "cvec.fit(df.process_text)\n",
    "cvec_counts = cvec.transform(df.process_text)\n",
    "occ = np.asarray(cvec_counts.sum(axis=0)).ravel().tolist()\n",
    "counts_df = pd.DataFrame({'term': cvec.get_feature_names(), 'occurrences': occ})\n",
    "counts_df.sort_values(by='occurrences', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>author</th>\n",
       "      <th>process_text</th>\n",
       "      <th>president</th>\n",
       "      <th>obama</th>\n",
       "      <th>president obama</th>\n",
       "      <th>great</th>\n",
       "      <th>trump</th>\n",
       "      <th>just</th>\n",
       "      <th>...</th>\n",
       "      <th>deal</th>\n",
       "      <th>doesnt</th>\n",
       "      <th>forward</th>\n",
       "      <th>obamas</th>\n",
       "      <th>act</th>\n",
       "      <th>bad</th>\n",
       "      <th>did</th>\n",
       "      <th>house</th>\n",
       "      <th>potus</th>\n",
       "      <th>making</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-10-14</td>\n",
       "      <td>Denying climate change is dangerous. Join @OFA...</td>\n",
       "      <td>BarackObama</td>\n",
       "      <td>denying climate change is dangerous join @ofa ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 104 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date                                               text       author  \\\n",
       "0 2016-10-14  Denying climate change is dangerous. Join @OFA...  BarackObama   \n",
       "\n",
       "                                        process_text  president  obama  \\\n",
       "0  denying climate change is dangerous join @ofa ...          0      0   \n",
       "\n",
       "   president obama  great  trump  just   ...    deal  doesnt  forward  obamas  \\\n",
       "0                0      0      0     0   ...       0       0        0       0   \n",
       "\n",
       "   act  bad  did  house  potus  making  \n",
       "0    0    0    0      0      0       0  \n",
       "\n",
       "[1 rows x 104 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_featurs = 100\n",
    "top_terms = counts_df.sort_values(by='occurrences', ascending=False)[:num_featurs].term.values\n",
    "\n",
    "def generate_features(text): \n",
    "    one_hot = np.zeros(shape=top_terms.shape, dtype=int)\n",
    "    for i, term in enumerate(top_terms): \n",
    "        for word in text.split(): \n",
    "            if word == term:\n",
    "                one_hot[i] = 1\n",
    "    return one_hot\n",
    "\n",
    "temp = df.process_text.apply(generate_features)\n",
    "temp = temp.apply(lambda x: pd.Series(x)) #split the vector into columns \n",
    "temp.columns = top_terms #rename \n",
    "df_feat = df.join(temp) \n",
    "df_feat.head(1) #spot check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import tree\n",
    "\n",
    "df_TREE = df_feat #[df_feat.author != 'HillaryClinton']\n",
    "\n",
    "### Cross Val Decision Tree ### \n",
    "# clf = tree.DecisionTreeClassifier(random_state=0)\n",
    "# scores = cross_val_score(clf, df_TREE.iloc[:, 4:], df_TREE.author, cv=10)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "# print (scores)\n",
    "\n",
    "### Decision Tree for Visualization ###\n",
    "\n",
    "split =  int(df_TREE.shape[0]* 0.9)\n",
    "\n",
    "clf = tree.DecisionTreeClassifier(random_state=0, \n",
    "                                 max_depth=3, #low for visibility \n",
    "                                 criterion = 'entropy')\n",
    "\n",
    "clf = clf.fit(X = df_TREE.iloc[:split, 4:],\n",
    "              y = df_TREE.author[:split])\n",
    "\n",
    "### Visualize ###\n",
    "dotfile = open(\"dtree2.dot\", 'w')\n",
    "tree.export_graphviz(clf, out_file = dotfile, feature_names = df_TREE.iloc[:, 4:].columns)\n",
    "dotfile.close()\n",
    "### dotfile --> png via cmd line  ###\n",
    "!dot -Tpng dtree2.dot -o tree.png\n",
    "from IPython.display import Image \n",
    "Image(filename='tree.png')\n",
    "!tree.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get word counts \n",
    "# text = df['process_text'].values\n",
    "# tokens = {}\n",
    "# for sample in text: \n",
    "#     for word in sample.split(): \n",
    "#         if word not in tokens:\n",
    "#             tokens[word] = 1\n",
    "#         else: \n",
    "#             tokens[word] += 1\n",
    "# print (len(tokens))\n",
    "\n",
    "# word_counts = pd.DataFrame([tokens.keys(), tokens.values()]).T\n",
    "# word_counts.columns = ['words', 'counts']\n",
    "\n",
    "# low_words = word_counts[word_counts['counts'] < 3].values\n",
    "# def remove_uncommon_words(text): \n",
    "#     text = text.split()\n",
    "#     for word in low_words: \n",
    "#         if word in text: \n",
    "#             text.remove(word)\n",
    "#     return ' '.join(text)\n",
    "\n",
    "# df['clean_text'] = df['process_text'].apply(remove_uncommon_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #create bigrams and unigrams \n",
    "# import nltk\n",
    "# df = df.dropna(axis=0)\n",
    "# def bigrams(text): \n",
    "#     text = text.split()\n",
    "#     bigram = nltk.bigrams(text)\n",
    "#     bigrams = [' '.join(x) for x in list(bigram)]\n",
    "#     return bigrams  + text\n",
    "    \n",
    "# df['bigrams'] = df['clean_text'].apply(bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #get word counts \n",
    "# text = df['bigrams'].values\n",
    "# tokens = {}\n",
    "# for sample in text: \n",
    "#     for word in sample: \n",
    "#         if word not in tokens:\n",
    "#             tokens[word] = 1\n",
    "#         else: \n",
    "#             tokens[word] += 1\n",
    "# print (len(tokens))\n",
    "\n",
    "# word_counts2 = pd.DataFrame([tokens.keys(), tokens.values()]).T\n",
    "# word_counts2.columns = ['words', 'counts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low_words = word_counts2[word_counts2.counts > 3].words.values\n",
    "# def remove_uncommon_words(text): \n",
    "#     text = text.split()\n",
    "#     for word in low_words: \n",
    "#         if word in text: \n",
    "#             text.remove(word)\n",
    "#     return ' '.join(text)\n",
    "\n",
    "# df['clean_text'] = df['process_text'].apply(remove_uncommon_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = df['bigrams'].apply(lambda x: pd.Series(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove words occuring fewer than 3 times \n",
    "# low_words = df3[df3['counts'] < 3].sort_values('counts', ascending=False)['words'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def reduce__words(text): \n",
    "#     for word in low_words: \n",
    "#         text = text.replace(word, '')\n",
    "#     return text\n",
    "\n",
    "# df['bigrams_clean'] = df.bigrams.apply(reduce__words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new = df['bigrams_clean'].apply(lambda x: pd.Series(x.split()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
